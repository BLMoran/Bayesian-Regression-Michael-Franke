---
title: "Bayesian regression: theory & practice"
subtitle: "07: Causal inference"
author: "Michael Franke"
format: html
editor: visual
execute:
  error: false
  warning: false
  message: false
callout-appearance: simple
---

{{< include 00-preamble.qmd >}}

# Simpson's paradox: puzzle and data

[Simpson's paradox](https://plato.stanford.edu/entries/paradox-simpson/) is a multi-faceted puzzle about how to analyse data, when the same data set can be interpreted differently, based on different assumptions about the causal relation between variables. The following uses a slight variation of a fictitious data set frequently used by Judea Pearl (e.g., in Pearl, Glymour and Jewell ("Causal Inference in Statistics: A primer", 2016)). There are two scenarios, to be introduced one after the other below, framed as data about the effect of a drug on the rate of recovery.

The most important objective of this tutorial is to calculate the *total causal effect* (TCE) of the drug in each scenario, following the approach outline by Pearl et al. (2016). We first calculate a maximum-likelihood estimate of the TCE and then a Bayesian estimate derived from regression modeling. The advantage of the latter is that it allows quantification of uncertainty of the TCE estimate.

## Case 1: Gender

In the first scenario (referred to as "Case 1: Gender as a confound"), the data was collected by the following procedure:

-   700 participants were recruited, out of which 357 identified as `male` and 343 identified as `350` female
-   each participant decides whether or not to take a new drug
-   we observe whether the patient recovered or not

Here is the data for the first scenario:

```{r}
##################################################
# set up the data for SP
##################################################

data_simpsons_paradox <- tibble(
  gender = c("Male", "Male", "Female", "Female"),
  bloodP = c("Low", "Low", "High", "High"),
  drug   = c("Take", "Refuse", "Take", "Refuse"),
  k      = c(81, 234, 192, 55),
  N      = c(87, 270, 263, 80),
  proportion = k/N
)

data_simpsons_paradox |> select(-bloodP)
```

Research Team 1 bends over this data set and notices that the drug increases recovery for both males and females, as shown in the plot below. Based on this, Research Team 1 concludes that the drug is effective and they recommend its usage.

```{r}
data_simpsons_paradox |> 
  ggplot(aes(x = drug, y = proportion, group = gender)) +
  geom_line(size = 1.2, color = project_colors[12]) + 
  geom_point(size = 3, aes(color = gender))
```

## Case 2: Blood pressure

But now consider a second scenario. Data was collected by the following process:

-   700 participants were recruited
-   each participant decides whether or not to take a new drug
-   each patient is assigned to a `high` and `low` blood pressure group, after a blood pressure measurement (if a patient took the drug, this measurement happens *after* having taken the drug)
-   we observe whether each patient recovered or not

The data for this scenario look as follows:

```{r }
data_simpsons_paradox |> select(-gender)
```

(Yes, you are right! The numbers are exactly the same as before!)

Research Team 2 bends over this data set and notices that the drug decreases recovery rate in the whole population, as shown in the plot below. Based on this, Research Team 2 concludes that the drug is *not* effective. They do *not* recommend it for usage.

```{r}
data_simpsons_paradox |>
  group_by(drug) |> 
  summarise(proportion = sum(k) / sum(N)) |> 
  ggplot(aes(x = drug, y = proportion)) +
  geom_line(size = 1.2, aes(group = 1), color = project_colors[12]) +
  geom_point(size = 3, aes(color = drug)) 
```

## What's the paradox?

The puzzle here is that two research teams have reached opposite conclusions based on data which is at least numerically the exact same. Each team seems, at first glance, to have drawn reasonable conclusions. How is it possible to reach opposite conclusions about whether or not to use a drug, based on the same set of numbers?

## Resolving the puzzle by causal analysis

You say: "The data sets are not the same! The numbers are, but in one case we observed `gender` and in the other we observed `blood pressure`. That makes a difference, doesn't it?"

I say: "Well, okay, but not necessarily. Just having different labels for levels of a categorical variable doesn't make for a different data set, does it?"

But you immediately shoot back: "Maybe, but you also told us about a difference in the data-generating process. There is at least a temporal difference: `blood pressure` is measured after the treatment, but the level of `gender` was fixed already before the treatment."

"Okay" I say. "So, do you suggest a temporal analysis?"

You roll your eyes and after a few more (ridiculous) turns of this conversation, we both agree that, at least conceptually speaking, there is a difference in the plausible *causal structure* of the involved variables.

Consider the first case. There are three binary variables involved. Given the temporal sequence of events in the data-generating process, the likely causal relation between the variables is that `gender` may influence both `drug` (the decision to take the drug or not) and `recovery`. Moreover, the `drug` may have influenced `recovery` directly.

![Causal structure of scenario 1: gender is a confound](../pics/Simpson-paradox-confound.pdf)

Now consider the second scenario. Again, we have three binary variables. But since `blood pressure` is measures *after* the treatment, it is not plausible that it could have influenced the decision of whether to take the drug or not. Reversely, it *is* plausible to assume, i.e., to at least allow for the possibility, that `blood pressure` was affected by gender and that it may have affected `recovery`. As before, we also make room for the possibility that `drug` may affect `recovery` also directly.

![Causal structure of scenario 2: blood pressure is a mediator](../pics/Simpson-paradox-mediator.pdf)

# Causal analysis with MLE

Following Pearl's approach to causal analysis, the most important quantity to assess is how (hypothetical) manipulations of administering the drug would influence the recovery rate. In other words, we would like to quantify the *total causal effect (TCE)*:

$$ P(R=1 \mid \mathit{do}(D=1)) - P(R=1 \mid \mathit{do}(D=0)) $$

as the difference in expected recovery rate in the imagined scenario that we could surgically change whether a drug was given, without changing non-causal dependencies of `drug`.

What it means to condition on "$\mathit{do}(D=d)$" depends on the assumed causal relationship between variables. So, we will look at each scenario in sequence.

## Case 1: Gender as a confound

Since the set $\{G\}$ statisfies the *backdoor criterion* for the assumed causal DAG, we know that we can calculate the total causal effect (TCE) by eliminating the *do*-operator in the conditioning using the *adjustment formula*:

$$
P(R=r \mid \mathit{do}(D=d)) = \sum_{g \in \{0,1\}} P(R=r \mid D=d, G=g) \ P(G=g)
$$

This means that we need to estimate two probability distributions: the conditional probability of recovery given `drug` and `gender` and the (marginal) probability of `gender`. We can use maximum-likelihood estimates for these by just using the observed frequencies as estimators. For $\mathit{do}(D=1)$, this yields:

$$
\begin{align*}
& P(R=1 \mid \mathit{do}(D=1)) 
\\
= &   P(R=1 \mid D=1, G=f) \ P(G=f) + P(R=1 \mid D=1, G=m) \ P(G=m)
\\
= &   \frac{192}{263} \ \frac{343}{700} 
    + \frac{81}{87}  \ \frac{357}{700}
\\
= & 0.8325462
\end{align*}
$$

For $\mathit{do}(D=0)$, we get:

$$
\begin{align*}
& P(R=1 \mid \mathit{do}(D=0)) 
\\
= &   P(R=1 \mid D=0, G=f) \ P(G=f) + P(R=1 \mid D=0, G=m) \ P(G=m)
\\
= &   \frac{55}{80} \ \frac{343}{700} 
    + \frac{234}{270}  \ \frac{357}{700}
\\
= & 0.778875
\end{align*}
$$ So, an ML-estimate of the TCE would be:

```{r}
192/263 * 343/700 + 81/87 * 357/700 -
  (55/80 * 343/700 + 234/270 * 357/700)
```

This suggest that the drug is effectively increasing expected recovery, but we do not have a measure of uncertainty of this estimate. We don't know if we should consider this convincing evidence to recommend wide-spread adoption. That's why we need (something like) Bayesian estimation eventually. But let's first look at the second scenario.

## Case 2: Blood pressure as a mediator

For the causal graph assumed for the second scenario, the *do*-intervention reduces to the conditional probability:

$$
P\left(R=1 \mid \mathit{do}(D=d)\right) 
= P\left(R = 1 \mid D=d \right)
$$

For $\mathit{do}(D=1)$, this yields:

$$
P(R=1 \mid \mathit{do}(D=1)) = P(R=1 \mid D=1) = \frac{273}{350} = 0.78
$$

For $\mathit{do}(D=0)$, we get:

$$
P(R=1 \mid \mathit{do}(D=0)) = P(R=1 \mid D=0) = \frac{289}{350} = 0.8257143
$$

The ML-esimtate of the TCE is therefore:

```{r}
273/350 - 289/350
```

This differs in sign from the previous estimate, and we might conclude that administering the drug is, overall, *not* beneficial. Yet, again, we have no uncertainty quantification regarding this estimate.

# Bayesian causal effect estimation

Let's use Bayesian regression modelling to calculate the total causal effects for each scenario.

## Some data wrangling

For subsequent analysis (especially when generating predictive samples), it helps to have the data in long format. The `uncount()` function is a great tool for this.

```{r}
# cast into long format
data_SP_long <- rbind(
  data_simpsons_paradox |> uncount(k) |> 
    mutate(recover = TRUE)  |> select(-N, -proportion),
  data_simpsons_paradox |> uncount(N-k) |> 
    mutate(recover = FALSE) |> select(-N, -proportion, -k)
)
data_SP_long
```

## Case 1: Gender as a confound

Given the causal structure assumed for scenario 1, we can calculate:

$$
P(R=1 \mid \mathit{do}(D=d)) = \sum_{g \in \{0,1\}} P(R=1 \mid D=d, G=g) \ P(G=g)
$$ Therefore, we need to do three things:

1.  We estimate $P(R=1 \mid D=d, G=g)$. This can be done with a logistic regression model, regressing $R$ on $D$ and $G$.
2.  We estimate $P(G)$, which we can do with an intercept-only logistic regression model.
3.  We calculate the TCE based on samples from the posterior predictive distribution of these models.

### Step 1: Intercept-only model for `gender`

Here is an intercept-only logistic regression model for `gender`:

```{r}
#| warning: false
#| error: false
#| results: hide

niter = 4000

fit_SP_GonIntercept <- brm(
  formula = gender ~ 1,
  data    = data_SP_long,
  family  = bernoulli(link = "logit"),
  iter    = niter
)
```

Each sample from the posterior of the `Intercept` parameter represents (a guess of) the log-odds of the `Male` category. The posterior over the proportion of male participants can therefore be retrieved and plotted as follows (the yellow line shows the observed frequency):

```{r}
logistic <- function(x) {
  1 / (1 + exp(-x))
}

posterior_SP_GonIntercept <- tidybayes::tidy_draws(fit_SP_GonIntercept) |> 
  mutate(prop_male = logistic(b_Intercept)) |> 
  select(prop_male)

posterior_SP_GonIntercept |> 
  ggplot(aes(x = prop_male)) + 
  tidybayes::stat_halfeye() +
  geom_vline(aes(xintercept = 357/700), color = project_colors[3]) +
  xlab("proportion males") + 
  ylab("posterior density")
```

### Step 2: Regressing $R$ against $G$ and $D$

```{r}

fit_SP_RonGD <- brm(
  formula = recover ~ gender * drug,
  data    = data_SP_long,
  family  = bernoulli(link = "logit"),
  iter    = niter
)

# 3. get posterior predictive samples for model from step (2), based on
#    posterior predictive samples for model from step (1), while
#    setting D to 0 and 1

# obtain posterior predictive samples for the number of male participants:

postPred_males <- tidybayes::predicted_draws(
  object  = fit_SP_GonIntercept,
  newdata = tibble(Intercept = 1),
  value   = "gender",
  ndraws  = niter * 2
  ) |> 
  ungroup() |> 
  mutate(gender = ifelse(gender, "Male", "Female")) |> 
  select(gender)

# NB: in this case we could also have gotten this via: 
# rbinom(n=4000, p=rbeta(4000, 315+1, 700-315+1), size = 700)

# posterior predictive samples for D=1

posterior_DrugTaken <- tidybayes::epred_draws(
  object  = fit_SP_RonGD,
  newdata = postPred_males |> mutate(drug = "Take"),
  value   = "taken",
  ndraws  = niter * 2
) |> ungroup() |> 
  select(taken)

posterior_DrugRefused <- tidybayes::epred_draws(
  object  = fit_SP_RonGD,
  newdata = postPred_males |> mutate(drug = "Refuse"),
  value   = "refused",
  ndraws  = niter * 2
) |> ungroup() |> 
  select(refused)

CE_post <- cbind(posterior_DrugTaken, posterior_DrugRefused) |> 
  mutate(causal_effect = taken - refused) 

rbind(
  aida::summarize_sample_vector(CE_post$taken, "drug_taken"),
  aida::summarize_sample_vector(CE_post$refused, "drug_refused"),
  aida::summarize_sample_vector(CE_post$causal_effect, "causal_effect")
)

CE_post |> 
  ggplot(aes(x = causal_effect)) +
  tidybayes::stat_halfeye()
```

## Case 2: Blood pressure as a mediator

```{r}

###################################################
# SP2: blood pressure as a mediator
###################################################

# we just need to estimate P(R \mid D, B), so a single 
# regression model will do

fit_SP_RonBD <- brms::brm(
  formula = recover ~ drug,
  data    = data_SP_long,
  family  = bernoulli(link = "logit"),
  iter    = niter
)

posterior_DrugTaken <- 
  faintr::extract_cell_draws(fit_SP_RonBD, drug == "Take") |> 
  pull(draws) |> 
  logistic()

posterior_DrugRefused <- 
  faintr::extract_cell_draws(fit_SP_RonBD, drug == "Refuse") |> 
  pull(draws) |> 
  logistic()

posterior_causalEffect <- 
  posterior_DrugTaken - posterior_DrugRefused

rbind(
  aida::summarize_sample_vector(posterior_DrugTaken, "drug_taken"),
  aida::summarize_sample_vector(posterior_DrugRefused, "drug_refused"),
  aida::summarize_sample_vector(posterior_causalEffect, "causal_effect")
  
)

# This is the total causal effect! 
# We will not go into computing "direct causal effects" in the 
#   presence of mediators.




```
