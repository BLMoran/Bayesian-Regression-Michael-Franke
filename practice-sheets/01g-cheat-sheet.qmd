---
title: "Cheat sheet: common things to do with BRMS"
subtitle: "Bayesian regression: theory & practice"
author: "Michael Franke"
format: html
editor: visual
execute:
  error: false
  warning: false
  message: false
  cache: true
callout-appearance: simple
---

This document provides a cursory run-down of common operations and manipulations for working with the `brms` package.

# Preamble

{{< include 00-preamble.qmd >}}

# Running a regression model

As a running example, we fit a multi-level model.

```{r}
#| results: hide

data_MC <- aida::data_MC_preprocessed |> 
      mutate(condition = factor(as.character(block), 
                                levels = c("goNoGo", "reaction", "discrimination")))

fit_MC <- 
  brms::brm(
    # "brmsformula" object specifies the model to fit
    formula = RT ~ condition + (1 + condition + shape | submission_id),
    # data to fit model to
    data = data_MC,
    # "iter" is the number of iterations
    iter = 4000,
    # control parameters for MCMC
    control = list(adapt_delta = 0.9)
  )
```

## Updating a model

Using `stats::update()`, refit a model based on an existing model fit, keeping everything as is, except for what is explicitly set:

```{r}
#| eval: false

# take existing fit, refit on smaller data set, just take 100 samples (all else equal)
fit_first_five <- 
  stats::update(
    object = fit_MC,
    iter = 100,
    # use first five participants only
    newdata = data_MC |> filter(submission_id >= 8550)
  )

```

# General information about the model fit

## Summaries

Standard summary of the model fit:

```{r}
summary(fit_MC)
```

Same in tidy format:

```{r}
tidybayes::summarise_draws(fit_MC)
```

Summary of just the fixed effects:

```{r}
brms::fixef(fit_MC)
```

Summary of just the random effects (this is huge, so output suppressed):

```{r}
#| eval: false
brms::ranef(fit_MC)
```

## Retrieve names of model variables

```{r }
tidybayes::get_variables(fit_MC)[1:10]
```

# MCMC diagnostics

[fill me]{style="color:darkgreen"}

# Extracting samples

## Tidy samples with `tidybayes`

Retrieve all samples with `tidybayes::tidy_draws()`:

```{r}
tidybayes::tidy_draws(fit_MC)
```

## Getting summaries for samples

To get (Bayesian) summary statistics for a vector of samples from a parameter you can do this:

```{r}
posterior_Intercept <- 
  tidybayes::tidy_draws(fit_MC) |> 
  dplyr::pull("b_Intercept")
```

The `tidybayes::hdi` function gives the upper and lower bound of a Bayesian credible interval:

```{r}
tidybayes::hdi(posterior_Intercept, credMass = 0.90)
```

The function `aida::summarize_sample_vector` does so, too.

```{r}
aida::summarize_sample_vector(posterior_Intercept, name = "Intercept")
```

Here is how you can do this for several vectors at once:

```{r}
tidybayes::tidy_draws(fit_MC) |> 
  dplyr::select(starts_with("b_")) |> 
  pivot_longer(cols = everything()) |> 
  group_by(name) |> 
  reframe(aida::summarize_sample_vector(value)[-1])
```

# Plotting posteriors

[fill me]{style="color:darkgreen"}

-   population and group level effects

# Posterior predictives

## Visual PPCs

## Extracting samples from the posterior predictive distribution

There are three kinds of commonly relevant variables a generalized linear model predicts:

1.  the central tendency of data $y$ for some predictor $x$,
2.  the shape of the (hypothetical) data $y'$ for $x$, and
3.  a linear predictor value given values of $x$.

All of these measures can be obtained from a fitted model with different functions, e.g., from the `tidyverse` package. Here, it does not matter whether the model was fitted to data or it is a "prior model", so to speak, fit with the flag `sample_prior = "only"`.

Here is an example for a logistic regression model (where all the three measures clearly show their conceptual difference).

```{r}
#| results: hide
fit_MT_logistic <- 
  brms::brm(
    formula = correct ~ group * condition,
    data    = aida::data_MT,
    family  = brms::bernoulli()
  )
```

```{r}
# 2 samples from the predicted central tendency
aida::data_MT |> 
  dplyr::select(group, condition) |> 
  unique() |> 
  tidybayes::add_epred_draws(
    fit_MT_logistic,
    ndraws = 2
    )

# 2 samples from the predictive distribution (data samples)
aida::data_MT |> 
  dplyr::select(group, condition) |> 
  unique() |> 
  tidybayes::add_predicted_draws(
    fit_MT_logistic,
    ndraws = 2
    )

# 2 samples for the linear predictor
aida::data_MT |> 
  dplyr::select(group, condition) |> 
  unique() |> 
  tidybayes::add_linpred_draws(
    fit_MT_logistic,
    ndraws = 2
    )
```

# Priors

## Inspecting default priors without running the model

```{r}
# define the model as a "brmsformula" object
myFormula <- brms::bf(RT ~ 1 + condition + (1 + condition | submission_id))

# get prior information
brms::get_prior(
  formula = myFormula,
  data    = data_MC,
  family  = exgaussian()
  )
```

## Setting priors

```{r}
#| eval: false

myPrior <- 
  brms::prior("normal(30,100)",  class = "b", coef = "conditiondiscrimination") +
  brms::prior("normal(-30,100)", class = "b", coef = "conditionreaction")

fit_with_specified_prior <- 
  brms::brm(
    formula = myformula,
    data    = data_MC,
    prior   = myPrior,
    family  = exgaussian()
  )
```

## Sampling from the prior

```{r}
#| eval: false

fit_samples_from_prior_only <- 
brms::brm(
  formula = myformula,
  data    = data_MC,
  prior   = myPrior,
  family  = exgaussian(),
  sample_prior = "only"
)
```

# Under the hood: Stan code, design matrices etc.

## Extract the Stan code

```{r}
brms::stancode(fit_MC)
```

## Extract Stan data

This is the data passed to Stan. Useful for inspecting dimensions etc.

```{r}
brms::standata(fit_MC) |> names()
```

## Inspect design matrices

### Population-level effects

```{r}
X <- brms::standata(fit_MC)$X
X |> head()
```

### Group-level effects

The group-level design matrix is spread out over different variables (all names `Z_` followed by some indices), but retrievable like so:

```{r}
data4Stan <- brms::standata(fit_MC)
Z <- data4Stan[str_detect(data4Stan |> names(), "Z_")] |> as_tibble()
Z
```
